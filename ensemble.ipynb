{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "SEED = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', usecols=['item_id'])\n",
    "train = pd.read_csv('data/train.csv', usecols=['item_id', 'deal_probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = pd.read_csv('predictions/periods.csv')\n",
    "periods_train = pd.read_csv('predictions/periods_train.csv').rename(columns={'deal_probability': 'periods_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_date = pd.read_csv('predictions/activation_date.csv')\n",
    "activation_date_train = pd.read_csv('predictions/activation_date_train.csv').rename(columns={'deal_probability': 'activation_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular = pd.read_csv('predictions/tabular.csv')\n",
    "tabular_train = pd.read_csv('predictions/tabular_train.csv').rename(columns={'deal_probability': 'tabular_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pd.read_csv('predictions/nlp.csv')\n",
    "nlp_train = pd.read_csv('predictions/nlp_train.csv').rename(columns={'deal_probability': 'nlp_predicted'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ensembling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = train.merge(periods_train, how='left', on='item_id')\n",
    "# train = train.merge(activation_date_train, how='left', on='item_id')\n",
    "# train = train.merge(tabular_train, how='left', on='item_id')\n",
    "# train = train.merge(nlp_train, how='left', on='item_id')\n",
    "\n",
    "train = reduce(lambda left,right: pd.merge(left,right,on='item_id', how='left'), \n",
    "              [train, periods_train, activation_date_train, tabular_train, nlp_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                   0.0\n",
       "periods_weight            0.0\n",
       "tabular_weight            0.0\n",
       "nlp_weight                0.0\n",
       "activation_date_weight    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = reduce(lambda left,right: pd.merge(left,right,on='item_id', how='left'), \n",
    "              [test, periods, activation_date, tabular, nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('deal_probability', axis=1), \n",
    "                                                    train['deal_probability'], \n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from utils import config_dict\n",
    "# model = RandomForestRegressor(n_estimators=200, random_state=SEED)\n",
    "model = RandomizedSearchCV(estimator=RandomForestRegressor(), random_state=SEED,\n",
    "                        param_distributions=config_dict['sklearn.ensemble.RandomForestRegressor'],\n",
    "                        n_iter=25,\n",
    "                        scoring='r2',\n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['deal_probability'] = model.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['deal_probability'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(periods, how='left', on='item_id')\n",
    "null_idx = test['deal_probability'].isna()\n",
    "test = test.rename(columns={'deal_probability': 'periods'})\n",
    "test['periods_weight'][null_idx] = 0.0\n",
    "test['periods'][null_idx] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(tabular, how='left', on='item_id')\n",
    "null_idx = test['deal_probability'].isna()\n",
    "test = test.rename(columns={'deal_probability': 'tabular'})\n",
    "test['tabular_weight'][null_idx] = 0.0\n",
    "test['tabular'][null_idx] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(nlp, how='left', on='item_id')\n",
    "null_idx = test['deal_probability'].isna()\n",
    "test = test.rename(columns={'deal_probability': 'nlp'})\n",
    "test['nlp_weight'][null_idx] = 0.0\n",
    "test['nlp'][null_idx] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(activation_date, how='left', on='item_id')\n",
    "null_idx = test['deal_probability'].isna()\n",
    "test = test.rename(columns={'deal_probability': 'activation_date'})\n",
    "test['activation_date_weight'][null_idx] = 0.0\n",
    "test['activation_date'][null_idx] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['deal_probability'] = test['periods']*test['periods_weight'] + \\\n",
    "                            test['tabular']*test['tabular_weight'] + \\\n",
    "                            test['nlp']*test['nlp_weight'] + \\\n",
    "                            test['activation_date']*test['activation_date_weight'] \n",
    "test['deal_probability'] /= ( test['periods_weight'] + test['tabular_weight'] + test['nlp_weight'] + test['activation_date_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['item_id', 'deal_probability']].set_index('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deal_probability    0.001718\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### methods for transformation to [0, 1] range:\n",
    "### 1) just cut out the negative part:\n",
    "submission[submission < 0] = 0.0\n",
    "\n",
    "### 2) MinMaxScaler to [0,1] range\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# submission['deal_probability'] = scaler.fit_transform(submission)\n",
    "\n",
    "submission.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6544e41a8817</th>\n",
       "      <td>0.053102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65b9484d670f</th>\n",
       "      <td>0.360651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bab230b2ecd</th>\n",
       "      <td>0.188644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e348601fefc</th>\n",
       "      <td>0.362879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bd2fe400b89</th>\n",
       "      <td>0.218020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              deal_probability\n",
       "item_id                       \n",
       "6544e41a8817          0.053102\n",
       "65b9484d670f          0.360651\n",
       "8bab230b2ecd          0.188644\n",
       "8e348601fefc          0.362879\n",
       "8bd2fe400b89          0.218020"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
